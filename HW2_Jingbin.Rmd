---
title: "HW2_Jingbin"
author: "Jingbin Xu"
date: "8/30/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include = FALSE, eval = TRUE, cashe = TRUE)
library(data.table)
library(tidyverse)
library(magrittr)
```
  
# Problem 3

Version control helps me collaborate with other team members, and we could reverse back if any mistakes or changes happened.

# Problem 4

# a. Sensory data from five operators
We are looking at the sensory data from Wu and Hamada's textbook: <http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/Sensory.dat>. 

First, we will get the data from the link above:

```{r sensory_data_import, cache=F,include=T}
# getting "<http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/Sensory.dat>"

url_sensory <- "http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/Sensory.dat"
#sensory_data_raw <- fread(url_sensory, header = F, fill = T, data.table = F)

# Save data as RDS format to protect against the website going down 

#saveRDS(sensory_data_raw, "sensory_data_raw.RDS")
sensory_data_raw <- readRDS("sensory_data_raw.RDS")
```

Next, we proceed to data clearning with base R function.
```{r sensory_tidy_baseR, cache=F, include=T, warning=F}
# Data cleaning to fix the NA and creat columns
# Romove first two row
# dim(sensory_data_raw)
sensory_data <- sensory_data_raw[-1:-2, ]
sensory_data$V1<- as.numeric(sensory_data$V1)

# Indexing the dimension of the dataset
nrow <- dim(sensory_data)[1]
ncol <- dim(sensory_data)[2]

# Remove the NA values in the dataset
for (i in 1:nrow) {
  if (is.na(sensory_data[i,ncol])){
    sensory_data[i,1:ncol] <- c(sensory_data[i-1,1],sensory_data[i,1:ncol-1])
  }
}
# Rename the columns by item and operator

colnames(sensory_data) <- c("Item", "Operator1", "Operator2", "Operator3", 
                            "Operator4", "Operator5")
# Rename the level of the items
sensory_data$Item <- as.factor(sensory_data$Item)
levels(sensory_data$Item) <- c("One", "Two", "Three", "Four", "Five", 
                               "Six", "Seven", "Eight", "Nine", "Ten")
```

Then, by using tidyverse, we could group data by item and operator.

```{r sensory_tidy_tidyR, cache=F, include=T, message=F, warning=F}
# Explore the datset by item, operator, value
sensory_data_tv <- sensory_data %>% 
  gather(key = "Operator", value = "Value", 
         "Operator1", 
         "Operator2", 
         "Operator3", 
         "Operator4", 
         "Operator5")

# Explore the mean by item and operator
summary_sensory <- sensory_data_tv %>% 
  group_by(Item) %>% 
  summarize(Avg = mean(Value, 2)) %>% 
  arrange(Item)

```

Finally, we could present the table.

```{r sensory_table, echo=F, include=T, eval=T}
knitr::kable(summary(sensory_data), caption="Sensory data summary by Base R")
knitr::kable(summary_sensory, caption="Sensory data summary by Tidyverse")
```

# b. Gold Mmdal performance for Olympic men's long jump
We are looking at the sensory data from Wu and Hamada's textbook:
<http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/LongJumpData.dat>

First we will get the data from the link above:

```{r jump_data_import, echo=T, include=T, eval=T}
# getting "https://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/LongJumpData.dat"
url_lj <- "https://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/LongJumpData.dat"
longjump_data_raw <- fread(url_lj, fill=TRUE, skip = 1, data.table = FALSE)
colnames(longjump_data_raw) <- c("year1", "jump1",
                                 "year2", "jump2",
                                 "year3", "jump3",
                                 "year4", "jump4")
saveRDS(longjump_data_raw, "longjump_data_raw.RDS")
longjump_data_raw <- readRDS("longjump_data_raw.RDS")
```

Then, we clean the data using baseR function.

```{r jump_tidy_baseR, echo=T, include=T, eval=T}
# Get the column year of the jump data
longjump_data_year <- c(longjump_data_raw$year1, 
                        longjump_data_raw$year2,
                        longjump_data_raw$year3,
                        longjump_data_raw$year4)
# Get the column jump 
longjump_data_jump <- c(longjump_data_raw$jump1,
                        longjump_data_raw$jump2,
                        longjump_data_raw$jump3,
                        longjump_data_raw$jump4)
# Combine the column of year and jump, remove NA rows using na.omit
lj_data <- na.omit(as.data.frame(cbind(Year = longjump_data_year+1900, 
                                       Jump = longjump_data_jump)))
```

Next, we clean the data using tidyverse.

```{r jump_tidy_tidyR, echo=T, include=T, eval=T}
# Compute the average jump prior to 1950
lj_data_1950_less <- lj_data %>% filter(Year < 1950) %>% 
                                  summarise(Avg = mean(Jump))
# Compute the average jump later than 1950
lj_data_1950_more <- lj_data %>% filter(Year > 1950) %>% 
                                  summarise(Avg = mean(Jump))
# Summary statistics
summary_1950 <- as.data.frame(cbind(Year = c("< 1950", "> 1950"), 
                                    Junp = c(round(lj_data_1950_less[1, ],2), 
                                             round(lj_data_1950_more[1, ],2))))
```

We present the summarize table and have following findings.

* The plot shows as jump distance increasing over time. There may exists a linear trend.

```{r jump_table, echo=F, include=T, eval=T}
knitr::kable(summary(lj_data), caption="Jump data summary by Base R")
knitr::kable(summary_1950, caption="Jump data summary by Tidyverse")
plot(lj_data, main = "Jump Distance vs Year")
```
  
# c. Brain weight (g) and body weight (kg) for 62 species.

We obtained the data for brain weight and boday weight for 62 species from the following link:

<http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/BrainandBodyWeight.dat>  


```{r brain_data_import, cache=F,include=T}
# getting data
url_brain <- "https://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/BrainandBodyWeight.dat"
brain_data_raw <- fread(url_brain, header = T, fill = T)
saveRDS(brain_data_raw, "brain_data_raw.RDS")
brain_data_raw <- readRDS("brain_data_raw.RDS")
```

Next, we proceed to formulate new data using base R function.

```{r brain_tidy_baseR, cache=F, include=T, warning=F}
# Get the body weight column
body <- as.vector(unlist(c(brain_data_raw[, 1],
                           brain_data_raw[, 3],
                           brain_data_raw[, 5])))
# Get the brain weight column
brain <- as.vector(unlist(c(brain_data_raw[, 2],
                            brain_data_raw[, 4],
                            brain_data_raw[, 6])))
# Combine the dataset
b_data <- as.data.frame(cbind(Body = body,
                              Brain = brain))
```
    
Then, using tidyverse function to manipulate our data

```{r brain_tidy_tidyR, cache=F, include=T, warning=F}
# Top 5 brain weight 
top_5_brw <- b_data %>% top_n(5, Brain) %>% 
                      arrange(desc(Brain))
# Top 5 body weight  
top_5_bdw <- b_data %>% top_n(5, Body) %>% 
                      arrange(desc(Body))
```

We could summarize the folloing table and have following finding:

* By boxplots, we find that outliers exist in the dataset, we need to further examine the outliers.

```{r brain_table, echo=F, include=T, eval=T}
knitr::kable(summary(b_data), caption="Brain and body data summary by Base R")
knitr::kable(top_5_bdw, caption="Top 5 body weight data summary by Tidyverse")
knitr::kable(top_5_brw, caption="Top 5 brain weight data summary by Tidyverse")
par(mfrow = c(1,2))
boxplot(b_data$Brain, main = "Brain weight (g)")
boxplot(b_data$Body, main = "Body weight (kg)")
```


# d. Triplicate measurements of tomato yield

By the following website link, we obtained our dataset for triplicate measurements of tomato yield.
<http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/tomato.dat>  

First, let's import the web data.

```{r measure_data_import, echo=T, include=T, eval=T}
# getting "https://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/tomato.dat"
url_to <- "https://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/tomato.dat"
to_data_raw <- fread(url_to, header = F)
saveRDS(to_data_raw, "to_data_raw.RDS")
to_data_raw <- readRDS("to_data_raw.RDS")
```

```{r measure_tidy_baseR, cache=F, include=T, warning=F}
## Convert columns and rows
# group 1: lfe
yield_10_g1 <- as.numeric(unlist(str_split(to_data_raw[1,2], ","), recursive = T))
yield_20_g1 <- as.numeric(unlist(str_split(to_data_raw[1,3], ","), recursive = T))
yield_30_g1 <- as.numeric(unlist(str_split(to_data_raw[1,4], ","), recursive = T))

# group 2: pusa
yield_10_g2 <- as.numeric(unlist(str_split(to_data_raw[2,2], ","), recursive = T))[1:3]
yield_20_g2 <- as.numeric(unlist(str_split(to_data_raw[2,3], ","), recursive = T))
yield_30_g2 <- as.numeric(unlist(str_split(to_data_raw[2,4], ","), recursive = T))

# combine data to dataframe
to_data <- data.frame(group1 = c(yield_10_g1, yield_20_g1, yield_30_g1),
                         group2 = c(yield_10_g2, yield_20_g2, yield_30_g2),
                         density = as.factor(sort(rep(c(10,20,30), 3))))
```

```{r measure_tidy_tidyR, cache=F, include=T, warning=F}
# Compute the avg of measure for group 1 by density
to_data_group1 <- to_data %>% group_by(density) %>% 
  summarise(Avg = mean(group1,2))
# Compute the avf of measure for group 2 by density
to_data_group2 <- to_data %>% group_by(density) %>% 
  summarise(Avg = mean(group2,2))
# Combine table
summary_dens <- as.data.frame(cbind(Group1 = to_data_group1,
                                    Group2 = to_data_group2))

```

Then we finalize with the summary table. And have the following finding:

* Overall, group 1 has relatively higher measure of tomatoes than group 2.

```{r measure_table, echo=F, include=T, eval=T}
knitr::kable(summary(to_data), caption="Tomato measure data summary by Base R")
knitr::kable(summary_dens, caption="Tomato measure data summary by Tidyverse")
boxplot(to_data[, 1:2], main = "Boxplot for tomatoes measure",
        ylab = "Density (per 1000)")
```

## Problem 5

Finish this homework by pushing your changes to your repo.  In general, your workflow for this should be:  

1. git pull -- to make sure you have the most recent repo  
2. In R: do some work  
3. git add -- this tells git to track new files  
4. git commit -- make message INFORMATIVE and USEFUL  
5. git push -- this pushes your local changes to the repo  

If you have difficulty with steps 1-5, git is not correctly or completely setup.  See me for help.

**Only submit the .Rmd and .pdf solution files.  Names should be formatted HW2_lastname.Rmd and HW2_lastname.pdf**